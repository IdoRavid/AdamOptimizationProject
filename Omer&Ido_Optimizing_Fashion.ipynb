{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osfFbOiTGXn0"
      },
      "source": [
        "## Imports and stting functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1ZW1kjTFO24",
        "outputId": "f7e3d4e8-1d20-478e-ce46-d5e03e31f6aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Clone code from GitHub\n",
        "!git clone https://github.com/IdoRavid/AdamOptimizationProject.git /content/project 2>/dev/null || (cd /content/project && git pull)\n",
        "%cd /content/project\n",
        "\n",
        "# Mount Drive for saving results\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "RESULTS_DIR = '/content/drive/MyDrive/Optimization Project/results/'\n",
        "!mkdir -p \"$RESULTS_DIR\"\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, 'src')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/project\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "eKkkKJ0qDYb8"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yft3XDWxDTPg",
        "outputId": "ebae20d5-8e91-4b27-9556-aa2befedd27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Data...\n"
          ]
        }
      ],
      "source": [
        "# @title Data Loader\n",
        "print(\"Loading Data...\")\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "train_data = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_data = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "x_train = train_data.data\n",
        "x_test = test_data.data\n",
        "image_size = x_train.shape[1] * x_train.shape[2]\n",
        "x_train = x_train.reshape(-1, image_size).float() / 255\n",
        "x_test = x_test.reshape(-1, image_size).float() / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ykXQg9hDDor7",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title AutoEncoder\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(image_size, 256), nn.ReLU(),\n",
        "            nn.Linear(256, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 32)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 128), nn.ReLU(),\n",
        "            nn.Linear(128, image_size), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_ill-I0HBJb"
      },
      "outputs": [],
      "source": [
        "#init autoencoder\n",
        "autoencoder = Autoencoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bakHXzqJa_eL"
      },
      "source": [
        "## oracle functions\n",
        "you should use to given model, loss function and x returns either the model output, the loss, the gradient and the hessian."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-20Y4GO_ECuk"
      },
      "outputs": [],
      "source": [
        "def autoencoder_oracle(model, criterion, x, calc_hessian=False):\n",
        "    \"\"\"\n",
        "    Computes f(x), gradient, and Hessian for a given input x.\n",
        "    \"\"\"\n",
        "    # Forward Pass\n",
        "    reconstructed_x = model(x)\n",
        "    loss = criterion(reconstructed_x, x)\n",
        "\n",
        "    grads = torch.autograd.grad(loss, model.parameters(), create_graph=calc_hessian)\n",
        "\n",
        "    hessians = []\n",
        "\n",
        "    if calc_hessian:\n",
        "        for i, (grad, param) in enumerate(zip(grads, model.parameters())):\n",
        "\n",
        "            grad_flat = grad.view(-1)\n",
        "\n",
        "            hessian_rows = []\n",
        "            for j in range(len(grad_flat)):\n",
        "\n",
        "                grad_2nd = torch.autograd.grad(grad_flat[j], param, retain_graph=True)[0]\n",
        "                hessian_rows.append(grad_2nd.view(-1))\n",
        "\n",
        "            hessian_matrix = torch.stack(hessian_rows)\n",
        "            hessians.append(hessian_matrix)\n",
        "\n",
        "\n",
        "    return loss, grads, hessians"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu0KkS3fD4Nm",
        "outputId": "541d9926-650b-4d62-f988-f7a2f262fb01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing the model (Defining the function surface)...\n"
          ]
        }
      ],
      "source": [
        "print(\"Initializing the model (Defining the function surface)...\")\n",
        "train_dataset = TensorDataset(x_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# This dataset is for the second order learners - so you wont run out of RAM\n",
        "small_train_dataset = TensorDataset(x_train[:100]) # רק 100 תמונות להדגמה\n",
        "small_train_loader = DataLoader(small_train_dataset, batch_size=10, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCrXpA4MgRLv"
      },
      "source": [
        "## Examples for optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3cN2BFTELxW"
      },
      "outputs": [],
      "source": [
        "def gd_step(x, grad_f_x, learning_rate=0.1):\n",
        "    \"\"\"\n",
        "    Performs one step of Gradient Descent.\n",
        "    Formula: x_new = x - lr * gradient\n",
        "    \"\"\"\n",
        "    x_new = x - learning_rate * grad_f_x\n",
        "\n",
        "    return x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3wszF7YERNy"
      },
      "outputs": [],
      "source": [
        "def newton_step(x, grad_f_x, hessian_f_x, learning_rate=1.0):\n",
        "    \"\"\"\n",
        "    Performs one step of Newton-Raphson optimization on a batch.\n",
        "    Shapes:\n",
        "      x: (Batch, Dim)\n",
        "      grad_f_x: (Batch, Dim)\n",
        "      hessian_f_x: (Batch, Dim, Dim)\n",
        "    \"\"\"\n",
        "    # 1. Calculate Inverse Hessian\n",
        "    # torch.linalg.pinv handles batch dimensions automatically (Batch, D, D)\n",
        "    hessian_inv = torch.linalg.pinv(hessian_f_x)\n",
        "\n",
        "    # 2. Prepare Gradient for Batch Matrix Multiplication\n",
        "    # grad_f_x is (Batch, D). We need (Batch, D, 1) for matmul\n",
        "    grad_unsqueezed = grad_f_x.unsqueeze(2)\n",
        "\n",
        "    # 3. Compute Update Direction: H^-1 * Gradient\n",
        "    # (Batch, D, D) x (Batch, D, 1) -> (Batch, D, 1)\n",
        "    update_direction = torch.matmul(hessian_inv, grad_unsqueezed)\n",
        "\n",
        "    # 4. Remove extra dimension: (Batch, D, 1) -> (Batch, D)\n",
        "    update_direction = update_direction.squeeze(2)\n",
        "\n",
        "    # 5. Apply Update\n",
        "    x_new = x - learning_rate * update_direction\n",
        "\n",
        "    return x_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3af72ae"
      },
      "outputs": [],
      "source": [
        "def run_model_optimization_experiment(\n",
        "    optimizer_type: str,\n",
        "    model: nn.Module,\n",
        "    criterion: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    epochs: int,\n",
        "    learning_rate: float\n",
        "):\n",
        "    \"\"\"\n",
        "    Runs an optimization experiment to train the MODEL using GD or Newton.\n",
        "    Closer to the requested structure.\n",
        "    \"\"\"\n",
        "    all_losses = []\n",
        "    print(f\"\\nStarting MODEL {optimizer_type.upper()} optimization for {epochs} epochs (lr={learning_rate})...\")\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            img = batch[0]\n",
        "\n",
        "            calc_hessian_for_oracle = (optimizer_type == 'newton')\n",
        "            loss, grads, hessians = autoencoder_oracle(model, criterion, img, calc_hessian=calc_hessian_for_oracle)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # 2. Optimization step\n",
        "            with torch.no_grad():\n",
        "                if optimizer_type == 'gd':\n",
        "                    for param, grad in zip(model.parameters(), grads):\n",
        "                        param.data = gd_step(param.data, grad, learning_rate)\n",
        "\n",
        "                elif optimizer_type == 'newton':\n",
        "                    if hessians is None:\n",
        "                        raise ValueError(\"Hessian missing for Newton method\")\n",
        "                    for param, grad, hessian in zip(model.parameters(), grads, hessians):\n",
        "                        param.data = newton_step(param.data, grad, hessian, learning_rate)\n",
        "\n",
        "                else:\n",
        "                    raise ValueError(\"Invalid optimizer type\")\n",
        "\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        all_losses.append(avg_loss)\n",
        "\n",
        "\n",
        "        if (epoch + 1) % (epochs // 5) == 0 or epoch == 0 or epoch == epochs - 1:\n",
        "            print(f\"  Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.6f}\")\n",
        "\n",
        "    total_end_time = time.time()\n",
        "    total_training_time = total_end_time - total_start_time\n",
        "    print(f\"\\nTotal Training Time: {total_training_time:.2f} seconds\")\n",
        "    print(f\"Finished {optimizer_type.upper()} optimization. Final Loss: {all_losses[-1]:.6f}\")\n",
        "    return model, all_losses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "lr = 0.1\n",
        "model = Autoencoder()\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "trained_model, losses = run_model_optimization_experiment(\n",
        "    'gd', model, criterion, train_loader, epochs, lr\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLFlHffz_pW7",
        "outputId": "eaee5f89-48b6-4a9f-d9c6-a7b3bde538dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting MODEL GD optimization for 10 epochs (lr=0.1)...\n",
            "  Epoch [1/10] Loss: 0.168506\n",
            "  Epoch [2/10] Loss: 0.161498\n",
            "  Epoch [4/10] Loss: 0.091319\n",
            "  Epoch [6/10] Loss: 0.084263\n",
            "  Epoch [8/10] Loss: 0.081242\n",
            "  Epoch [10/10] Loss: 0.079776\n",
            "Finished GD optimization. Final Loss: 0.079776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RiknlmI2DSnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12399dc4"
      },
      "source": [
        "### Loss Curves Over Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13cac4f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "ebaa8145-7456-43e3-99d4-02a9423b8a83"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses, label=f'GD (LR={lr})')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Optimization Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "475df8df"
      },
      "source": [
        "### Visual Comparison of Optimized Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf4b5052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "72368616-1a79-4cec-dcda-efdfde5cb0c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Visualizing Results...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x1500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def show_model_reconstructions(model, batch_images, count=5):\n",
        "    \"\"\"\n",
        "    Visualizes original images vs. model reconstructions.\n",
        "    \"\"\"\n",
        "    print(\"\\nVisualizing Results...\")\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        inputs = batch_images[:count]\n",
        "        reconstructions = model(inputs)\n",
        "\n",
        "    plt.figure(figsize=(8, 3 * count))\n",
        "\n",
        "    for i in range(count):\n",
        "        img_orig = inputs[i].cpu().numpy().reshape(28, 28)\n",
        "        img_recon = reconstructions[i].cpu().numpy().reshape(28, 28)\n",
        "\n",
        "        # Original\n",
        "        ax = plt.subplot(count, 2, i*2 + 1)\n",
        "        plt.imshow(img_orig, cmap='gray')\n",
        "        if i == 0: ax.set_title(\"Original\")\n",
        "        plt.axis('off')\n",
        "\n",
        "        #Reconstructed\n",
        "        ax = plt.subplot(count, 2, i*2 + 2)\n",
        "        plt.imshow(img_recon, cmap='gray')\n",
        "        if i == 0: ax.set_title(\"Reconstructed (Model Output)\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---use example ---\n",
        "data_iter = iter(train_loader)\n",
        "sample_images = next(data_iter)[0]\n",
        "\n",
        "show_model_reconstructions(trained_model, sample_images, count=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN29JrzwFO3a"
      },
      "source": [
        "## Custom Optimizer Implementation\n",
        "Variants: A1 (Adam+L2), B1-B8 (AdamW with different schedules)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUVzcHr_FO3a"
      },
      "source": [
        "# Import custom optimizers\n",
        "import sys\n",
        "sys.path.insert(0, 'src')\n",
        "\n",
        "from optimizers.base import OptimizerConfig\n",
        "from optimizers.adam_l2 import AdamL2\n",
        "from optimizers.adamw import AdamW, AdamWConfig\n",
        "from optimizers.schedulers import FixedLR, CosineLR, StepDropLR, WarmRestartsLR\n",
        "from optimizers.adafactor import Adafactor, AdafactorConfig\n",
        "from optimizers.combined import CombinedAdamWAdafactor, CombinedConfig"
      ],
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT-dwVdwFO3b"
      },
      "source": [
        "def create_optimizer(variant_id, model, epochs=100, batch_size=128, lr=1e-3, wd=1e-4,projection_spec=\"none\", track_projection_metrics=False):\n",
        "    \"\"\"Create optimizer by variant ID.\"\"\"\n",
        "    total_steps = epochs * (len(x_train) // batch_size)\n",
        "    total_batches = len(x_train) // batch_size * epochs\n",
        "\n",
        "    variants = {\n",
        "        'A1': lambda: AdamL2(model.parameters(), OptimizerConfig(lr=lr, weight_decay=wd)),\n",
        "        'B1': lambda: AdamW(model.parameters(), AdamWConfig(lr=lr, weight_decay=wd), FixedLR(), total_steps),\n",
        "        'B2': lambda: AdamW(model.parameters(), AdamWConfig(lr=lr, weight_decay=wd), StepDropLR(), total_steps),\n",
        "        'B3': lambda: AdamW(model.parameters(), AdamWConfig(lr=lr, weight_decay=wd), CosineLR(), total_steps),\n",
        "        'B4': lambda: AdamW(model.parameters(), AdamWConfig(lr=lr, weight_decay=wd), WarmRestartsLR(), total_steps),\n",
        "        'B5': lambda: AdamW(model.parameters(), AdamWConfig(lr=lr, weight_decay=wd, normalized_decay=True, total_batches=total_batches), FixedLR(), total_steps),\n",
        "        'B6': lambda: AdamW(model.parameters(), AdamWConfig(lr=lr, weight_decay=wd, normalized_decay=True, total_batches=total_batches), StepDropLR(), total_steps),\n",
        "        'B7': lambda: AdamW(model.parameters(), AdamWConfig(lr=lr, weight_decay=wd, normalized_decay=True, total_batches=total_batches), CosineLR(), total_steps),\n",
        "        'B8': lambda: AdamW(model.parameters(), AdamWConfig(lr=lr, weight_decay=wd, normalized_decay=True, total_batches=total_batches), WarmRestartsLR(), total_steps),\n",
        "        'C1': lambda: Adafactor(\n",
        "            model.parameters(),\n",
        "            AdafactorConfig(\n",
        "            lr=lr, beta1=0.0, weight_decay=wd,\n",
        "            projection_spec=projection_spec,\n",
        "            track_projection_metrics=track_projection_metrics,\n",
        "            ),\n",
        "            FixedLR(),\n",
        "            total_steps\n",
        "        ),\n",
        "        'C2': lambda: Adafactor(\n",
        "            model.parameters(),\n",
        "            AdafactorConfig(\n",
        "            lr=lr, beta1=0.9, weight_decay=wd,\n",
        "            projection_spec=projection_spec,\n",
        "            track_projection_metrics=track_projection_metrics,\n",
        "            ),\n",
        "            FixedLR(),\n",
        "            total_steps\n",
        "        ),\n",
        "\n",
        "        'D1': lambda: CombinedAdamWAdafactor(\n",
        "            model.parameters(),\n",
        "            CombinedConfig(\n",
        "                lr=lr, beta1=0.0, weight_decay=wd,\n",
        "                normalized_decay=True, total_batches=total_batches\n",
        "            ),\n",
        "            CosineLR(),\n",
        "            total_steps\n",
        "        ),\n",
        "        'D2': lambda: CombinedAdamWAdafactor(\n",
        "            model.parameters(),\n",
        "            CombinedConfig(\n",
        "                lr=lr, beta1=0.0, weight_decay=wd,\n",
        "                normalized_decay=True, total_batches=total_batches\n",
        "            ),\n",
        "            WarmRestartsLR(),\n",
        "            total_steps\n",
        "        ),\n",
        "        'D3': lambda: CombinedAdamWAdafactor(\n",
        "            model.parameters(),\n",
        "            CombinedConfig(\n",
        "                lr=lr, beta1=0.9, weight_decay=wd,\n",
        "                normalized_decay=True, total_batches=total_batches\n",
        "            ),\n",
        "            WarmRestartsLR(),\n",
        "            total_steps\n",
        "        )\n",
        "    }\n",
        "    return variants[variant_id]()\n",
        "\n",
        "VARIANT_NAMES = {\n",
        "    'A1': 'Adam+L2', 'B1': 'AdamW Fixed', 'B2': 'AdamW StepDrop', 'B3': 'AdamW Cosine',\n",
        "    'B4': 'AdamW WarmRestarts', 'B5': 'AdamW Fixed+Norm', 'B6': 'AdamW StepDrop+Norm',\n",
        "    'B7': 'AdamW Cosine+Norm', 'B8': 'AdamW WarmRestarts+Norm'\n",
        "        , 'C1': 'Adafactor (β1=0)', 'C2': 'Adafactor (β1=0.9)'\n",
        "    , 'D1': 'Combined Cosine+Norm', 'D2': 'Combined WarmRestarts+Norm', 'D3': 'Combined WarmRestarts+Norm (β1=0.9)'\n",
        "}"
      ],
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YZFi2Z9FO3d"
      },
      "source": [
        "def train_with_custom_optimizer(model, criterion, train_loader, optimizer, epochs=100):\n",
        "    \"\"\"Training loop using custom optimizer with oracle.\"\"\"\n",
        "    losses = []\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for batch in train_loader:\n",
        "            x = batch[0]\n",
        "            loss, grads, _ = autoencoder_oracle(model, criterion, x, calc_hessian=False)\n",
        "            for param, grad in zip(model.parameters(), grads):\n",
        "                param.grad = grad\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            epoch_loss += loss.item()\n",
        "        avg_loss = epoch_loss / len(train_loader)\n",
        "        losses.append(avg_loss)\n",
        "        if (epoch + 1) % 20 == 0 or epoch == 0:\n",
        "            print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}')\n",
        "    return losses"
      ],
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mye7DkuFFO3e"
      },
      "source": [
        "### Run Single Variant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "366y99LsFO3e"
      },
      "source": [
        "# Select variant and hyperparameters\n",
        "VARIANT = 'B3'  # Options: A1, B1-B8\n",
        "EPOCHS = 20\n",
        "LR = 1e-3\n",
        "WD = 1e-4\n",
        "\n",
        "model = Autoencoder()\n",
        "optimizer = create_optimizer(VARIANT, model, epochs=EPOCHS, lr=LR, wd=WD)\n",
        "print(f'Training {VARIANT}: {VARIANT_NAMES[VARIANT]}')\n",
        "losses = train_with_custom_optimizer(model, nn.MSELoss(), train_loader, optimizer, epochs=EPOCHS)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4irz2NxFFO3f"
      },
      "source": [
        "# Plot loss curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(losses, label=f'{VARIANT}: {VARIANT_NAMES[VARIANT]}')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSN1xJzrFO3f"
      },
      "source": [
        "# Show reconstructions\n",
        "show_model_reconstructions(model, next(iter(train_loader))[0], count=5)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QryBNy_5FO3g"
      },
      "source": [
        "## Grid Search for Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9f_s8g9FO3h"
      },
      "source": [
        "from utils.logging import TrainingLog\n",
        "from utils.experiment import GridSearchResult, OptimizerExperiment\n",
        "\n",
        "# Hyperparameter grid\n",
        "LR_MULTS = [1/1024, 1/512, 1/256, 1/128, 1/64, 1/32, 1/16, 1/8, 1/4, 1/2, 1, 2]\n",
        "WD_MULTS = [0, 1/32, 1/16, 1/8, 1/4, 1/2, 1, 2, 4, 8, 16, 32]\n",
        "BASE_LR = 1e-3\n",
        "BASE_WD = 1e-3"
      ],
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOLuojCQFO3h"
      },
      "source": [
        "def run_single_config(variant_id, lr, wd, epochs, batch_size, test_loader=None, log_every=10):\n",
        "    \"\"\"Train one config and return detailed log with test evaluation.\"\"\"\n",
        "    import time\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    model = Autoencoder().to(device)\n",
        "    opt = create_optimizer(variant_id, model, epochs=epochs, batch_size=batch_size, lr=lr, wd=wd)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    x_train_dev = x_train.to(device)\n",
        "    loader = DataLoader(TensorDataset(x_train_dev), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    if test_loader:\n",
        "        x_test_dev = test_loader.dataset.tensors[0].to(device)\n",
        "        test_loader = DataLoader(TensorDataset(x_test_dev), batch_size=batch_size)\n",
        "\n",
        "    log = TrainingLog()\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start = time.time()\n",
        "        epoch_loss = 0\n",
        "        for batch in loader:\n",
        "            x = batch[0]\n",
        "            model.zero_grad()\n",
        "            output = model(x)\n",
        "            loss = criterion(output, x)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        train_loss = epoch_loss / len(loader)\n",
        "\n",
        "        # Evaluate on test set\n",
        "        test_loss = train_loss\n",
        "        if test_loader:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                test_loss = sum(criterion(model(b[0]), b[0]).item() for b in test_loader) / len(test_loader)\n",
        "            model.train()\n",
        "\n",
        "        log.log_epoch(train_loss, test_loss, time.time() - epoch_start)\n",
        "\n",
        "    log.total_runtime = time.time() - start_time\n",
        "    return model, log"
      ],
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vcxyni8FO3h"
      },
      "source": [
        "def run_grid_search(variant_id, epochs=100, batch_size=128, save_every=1):\n",
        "    \"\"\"Run grid search with checkpointing and resume support.\"\"\"\n",
        "    filename = f'{variant_id}_{VARIANT_NAMES[variant_id].replace(\" \", \"_\")}.json'\n",
        "    filepath = RESULTS_DIR + filename\n",
        "\n",
        "    # Try to resume from existing file\n",
        "    try:\n",
        "        experiment = OptimizerExperiment.load(filepath)\n",
        "        done = {(r.lr_multiplier, r.wd_multiplier) for r in experiment.results}\n",
        "        print(f'Resuming {variant_id}: {len(done)} configs already done')\n",
        "    except:\n",
        "        experiment = OptimizerExperiment(\n",
        "            optimizer_id=variant_id,\n",
        "            optimizer_name=VARIANT_NAMES[variant_id],\n",
        "            config={'epochs': epochs, 'batch_size': batch_size, 'base_lr': BASE_LR, 'base_wd': BASE_WD}\n",
        "        )\n",
        "        done = set()\n",
        "\n",
        "    test_loader = DataLoader(TensorDataset(x_test), batch_size=batch_size, shuffle=False)\n",
        "    total = len(LR_MULTS) * len(WD_MULTS)\n",
        "\n",
        "    for lr_mult in LR_MULTS:\n",
        "        for wd_mult in WD_MULTS:\n",
        "            if (lr_mult, wd_mult) in done:\n",
        "                continue\n",
        "\n",
        "            lr = BASE_LR * lr_mult\n",
        "            wd = BASE_WD * wd_mult\n",
        "\n",
        "            model, log = run_single_config(variant_id, lr, wd, epochs, batch_size, test_loader)\n",
        "\n",
        "            experiment.results.append(GridSearchResult(\n",
        "                lr_multiplier=lr_mult, wd_multiplier=wd_mult,\n",
        "                learning_rate=lr, weight_decay=wd,\n",
        "                final_train_loss=log.epoch_train_losses[-1],\n",
        "                final_test_loss=log.epoch_test_losses[-1],\n",
        "                best_test_loss=log.best_test_loss,\n",
        "                best_epoch=log.best_epoch,\n",
        "            ))\n",
        "\n",
        "            n = len(experiment.results)\n",
        "            print(f'\\r{variant_id}: {n}/{total} | lr={lr:.2e}, wd={wd:.2e}, test={log.epoch_test_losses[-1]:.4f}', end='')\n",
        "\n",
        "            if n % save_every == 0:\n",
        "                experiment.save(filepath)\n",
        "\n",
        "    print()\n",
        "    experiment.save(filepath)\n",
        "    return experiment"
      ],
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZhNsKc2FO3i"
      },
      "source": [
        "# === CONFIGURATION ===\n",
        "PHASE = 1  # 1 = screening (30 epochs), 2 = full training (100 epochs)\n",
        "\n",
        "GRID_EPOCHS = 30 if PHASE == 1 else 100\n",
        "\n",
        "# Phase 1: all optimizers for screening\n",
        "# Phase 2: only winners (edit after Phase 1)\n",
        "VARIANTS_TO_RUN = ['A1', 'B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'C1', 'C2', 'D1', 'D2', 'D3']\n",
        "\n",
        "print(f'Phase {PHASE}: {GRID_EPOCHS} epochs, {len(VARIANTS_TO_RUN)} optimizers')\n",
        "print(f'Estimated time: ~{len(VARIANTS_TO_RUN) * 144 * GRID_EPOCHS / 50 * 6 / 60:.0f} hours')\n",
        "\n",
        "experiments = {}\n",
        "for v in VARIANTS_TO_RUN:\n",
        "    print(f'\\n=== {v}: {VARIANT_NAMES[v]} ===')\n",
        "    experiments[v] = run_grid_search(v, epochs=GRID_EPOCHS)\n",
        "    print(f'Saved to Drive: {v}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IskjPzcSFO3k"
      },
      "source": [
        "# Plot heatmaps (reloads from Drive if session disconnected)\n",
        "from utils.experiment import OptimizerExperiment\n",
        "\n",
        "# Reload experiments from Drive\n",
        "experiments = {}\n",
        "for v in VARIANTS_TO_RUN:\n",
        "    filename = f'{v}_{VARIANT_NAMES[v].replace(\" \", \"_\")}.json'\n",
        "    filepath = RESULTS_DIR + filename\n",
        "    try:\n",
        "        experiments[v] = OptimizerExperiment.load(filepath)\n",
        "        print(f'Loaded {v}: {len(experiments[v].results)}/144 configs')\n",
        "    except Exception as e:\n",
        "        print(f'Could not load {v}: {e}')\n",
        "\n",
        "if not experiments:\n",
        "    print(\"No experiments to plot!\")\n",
        "else:\n",
        "    fig, axes = plt.subplots(1, len(experiments), figsize=(8*len(experiments), 6))\n",
        "    if len(experiments) == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for ax, (v, exp) in zip(axes, experiments.items()):\n",
        "        exp.plot_heatmap(ax=ax, title=f'{v}: {exp.optimizer_name}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(RESULTS_DIR + 'heatmaps.png', dpi=150)\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByeQtDRbFO3m"
      },
      "source": [
        "### Load and Analyze Results Locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPfVEdt1FO3n"
      },
      "source": [
        "# Load saved results\n",
        "# exp = OptimizerExperiment.load('results/A1_Adam+L2.json')\n",
        "# exp.plot_heatmap()\n",
        "# print(f'Best config: lr={min(exp.results, key=lambda r: r.best_test_loss)}')"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cNifh-yEFO3o"
      },
      "cell_type": "markdown",
      "source": [
        "## Adafactor Projection Test\n",
        "\n",
        "This is a sandbox experiment to test projecting Adafactor's **factored second-moment running averages**\n",
        "(`vr`, `vc`) onto different convex sets.\n",
        "\n",
        "We run a short training (1 epoch for now) for C1 and C2 and log similarity metrics between `vr/vc` **before** and **after** projection (saved by the optimizer in `state[\"vr_pre_proj\"]`, `state[\"vc_pre_proj\"]`).\n"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "HMqvNCjkFO3p",
        "outputId": "cc2023b5-851b-409a-f152-019cb2334201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num projection specs: 15\n",
            "  none\n",
            "  nonneg\n",
            "  box:l=0,u=1e6\n",
            "  box:l=0,u=1\n",
            "  simplex:s=1.0\n",
            "  l2_ball:scale=param_rms,base=1,mult=1e-12\n",
            "  l2_ball:scale=param_rms,base=1,mult=1e-10\n",
            "  l2_ball:scale=param_rms,base=1,mult=1e-08\n",
            "  l2_ball:scale=param_rms,base=1,mult=1e-06\n",
            "  l2_ball:scale=param_rms,base=1,mult=0.0001\n",
            "  box:l=0,u=1e-12\n",
            "  box:l=0,u=1e-11\n",
            "  box:l=0,u=1e-10\n",
            "  box:l=0,u=1e-09\n",
            "  box:l=0,u=1e-08\n"
          ]
        }
      ],
      "execution_count": 37,
      "source": [
        "# --- runtime sweep specs (multiple L2 scales) ---\n",
        "\n",
        "# Multipliers you want to sweep for adaptive L2-ball\n",
        "L2_MULTS = [1e-12, 1e-10, 1e-8, 1e-6, 1e-4]\n",
        "# For the box proj\n",
        "BOX_US = [1e-12, 1e-11, 1e-10, 1e-9, 1e-8]\n",
        "\n",
        "# Build projection specs programmatically (no hardcoding) it is hardcoded\n",
        "PROJECTION_SPECS = [\"none\"] #, \"nonneg\"] #, \"box:l=0,u=1e6\",\"box:l=0,u=1\", \"simplex:s=1.0\"]\n",
        "PROJECTION_SPECS += [f\"l2_ball:scale=param_rms,base=1,mult={m}\" for m in L2_MULTS]\n",
        "PROJECTION_SPECS += [f\"box:l=0,u={u}\" for u in BOX_US]\n",
        "# Alternative scale option:\n",
        "# PROJECTION_SPECS += [f\"l2_ball:scale=vec_rms,base=1000,mult={m}\" for m in L2_MULTS]\n",
        "\n",
        "print(\"Num projection specs:\", len(PROJECTION_SPECS))\n",
        "for s in PROJECTION_SPECS:\n",
        "    print(\" \", s)"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8vNOwGQFO3p",
        "outputId": "2e749b96-e367-4325-e0aa-a197bcff30f0"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running spec='none' beta1=0.0 ...\n",
            "Running spec='none' beta1=0.9 ...\n",
            "Running spec='nonneg' beta1=0.0 ...\n",
            "Running spec='nonneg' beta1=0.9 ...\n",
            "Running spec='box:l=0,u=1e6' beta1=0.0 ...\n",
            "Running spec='box:l=0,u=1e6' beta1=0.9 ...\n",
            "Running spec='box:l=0,u=1' beta1=0.0 ...\n",
            "Running spec='box:l=0,u=1' beta1=0.9 ...\n",
            "Running spec='simplex:s=1.0' beta1=0.0 ...\n",
            "Running spec='simplex:s=1.0' beta1=0.9 ...\n",
            "Running spec='l2_ball:scale=param_rms,base=1,mult=1e-12' beta1=0.0 ...\n",
            "Running spec='l2_ball:scale=param_rms,base=1,mult=1e-12' beta1=0.9 ...\n",
            "Running spec='l2_ball:scale=param_rms,base=1,mult=1e-10' beta1=0.0 ...\n",
            "Running spec='l2_ball:scale=param_rms,base=1,mult=1e-10' beta1=0.9 ...\n",
            "Running spec='l2_ball:scale=param_rms,base=1,mult=1e-08' beta1=0.0 ...\n",
            "Running spec='l2_ball:scale=param_rms,base=1,mult=1e-08' beta1=0.9 ...\n",
            "Running spec='l2_ball:scale=param_rms,base=1,mult=1e-06' beta1=0.0 ...\n",
            "Running spec='l2_ball:scale=param_rms,base=1,mult=1e-06' beta1=0.9 ...\n",
            "Running spec='l2_ball:scale=param_rms,base=1,mult=0.0001' beta1=0.0 ...\n",
            "Running spec='l2_ball:scale=param_rms,base=1,mult=0.0001' beta1=0.9 ...\n",
            "Running spec='box:l=0,u=1e-12' beta1=0.0 ...\n",
            "Running spec='box:l=0,u=1e-12' beta1=0.9 ...\n",
            "Running spec='box:l=0,u=1e-11' beta1=0.0 ...\n",
            "Running spec='box:l=0,u=1e-11' beta1=0.9 ...\n",
            "Running spec='box:l=0,u=1e-10' beta1=0.0 ...\n",
            "Running spec='box:l=0,u=1e-10' beta1=0.9 ...\n",
            "Running spec='box:l=0,u=1e-09' beta1=0.0 ...\n",
            "Running spec='box:l=0,u=1e-09' beta1=0.9 ...\n",
            "Running spec='box:l=0,u=1e-08' beta1=0.0 ...\n",
            "Running spec='box:l=0,u=1e-08' beta1=0.9 ...\n",
            "Done. total runs: 30 elapsed_sec: 108.3601565361023\n",
            "Saved: results/optimizer_projection_test.json\n"
          ]
        }
      ],
      "execution_count": 38,
      "source": [
        "# =========================\n",
        "# Adafactor Projection Test: RUN (replace this whole cell)\n",
        "# =========================\n",
        "import os, json, time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# --- do NOT change blocks above; define locally only if missing ---\n",
        "if \"device\" not in globals():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "RESULTS_DIR = \"results/\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "def _norm(x: torch.Tensor) -> float:\n",
        "    return float(x.norm().item())\n",
        "\n",
        "def _maybe(x: torch.Tensor):\n",
        "    return x.detach() if torch.is_tensor(x) else x\n",
        "\n",
        "# knobs for the projection experiment\n",
        "SEED = 0\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "EPOCHS_PROJ = 1\n",
        "BATCH_SIZE_PROJ = 128\n",
        "MAX_BATCHES = 200\n",
        "LR_PROJ = 1e-3\n",
        "WD_PROJ = 1e-4\n",
        "\n",
        "# total_steps (only used if your Adafactor takes schedulers; define here anyway)\n",
        "steps_per_epoch = max(1, len(x_train) // BATCH_SIZE_PROJ) if \"x_train\" in globals() else MAX_BATCHES\n",
        "total_steps = EPOCHS_PROJ * steps_per_epoch\n",
        "\n",
        "# loader (expects x_train exists from earlier blocks)\n",
        "proj_loader = torch.utils.data.DataLoader(\n",
        "    torch.utils.data.TensorDataset(x_train),\n",
        "    batch_size=BATCH_SIZE_PROJ,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "def _cosine_sim(a: torch.Tensor, b: torch.Tensor, tol: float = 1e-12) -> float:\n",
        "    a = a.flatten()\n",
        "    b = b.flatten()\n",
        "    na = float(a.norm().item())\n",
        "    nb = float(b.norm().item())\n",
        "    if na < tol or nb < tol:\n",
        "        return float(\"nan\")\n",
        "    return float((a @ b).item() / (na * nb))\n",
        "\n",
        "def _rel_change(a: torch.Tensor, b: torch.Tensor, eps: float = 1e-12) -> float:\n",
        "    denom = a.norm().clamp_min(eps)\n",
        "    return float((b - a).norm() / denom)\n",
        "\n",
        "def run_one_projection_spec(projection_spec: str, beta1: float):\n",
        "    model = Autoencoder().to(device)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # ---- Create optimizer WITHOUT touching blocks above ----\n",
        "    # If you already have create_optimizer above and want to use it, use the first option.\n",
        "    if \"create_optimizer\" in globals():\n",
        "        opt = create_optimizer(\n",
        "            \"C1\" if beta1 == 0.0 else \"C2\",\n",
        "            model,\n",
        "            epochs=EPOCHS_PROJ,\n",
        "            batch_size=BATCH_SIZE_PROJ,\n",
        "            lr=LR_PROJ,\n",
        "            wd=WD_PROJ,\n",
        "            projection_spec=projection_spec,\n",
        "            track_projection_metrics=True,\n",
        "        )\n",
        "    else:\n",
        "        # fallback: construct Adafactor directly (requires Adafactor/AdafactorConfig/WarmRestartsLR already imported above)\n",
        "        opt = Adafactor(\n",
        "            model.parameters(),\n",
        "            AdafactorConfig(\n",
        "                lr=LR_PROJ,\n",
        "                weight_decay=WD_PROJ,\n",
        "                beta1=beta1,\n",
        "                projection_spec=projection_spec,\n",
        "                track_projection_metrics=True,\n",
        "            ),\n",
        "            WarmRestartsLR(),\n",
        "            total_steps,\n",
        "        )\n",
        "\n",
        "    step_metrics = []\n",
        "    losses = []\n",
        "\n",
        "    it = iter(proj_loader)\n",
        "    for step in range(MAX_BATCHES):\n",
        "        try:\n",
        "            batch = next(it)[0].to(device)\n",
        "        except StopIteration:\n",
        "            it = iter(proj_loader)\n",
        "            batch = next(it)[0].to(device)\n",
        "\n",
        "        loss, grads, _ = autoencoder_oracle(model, criterion, batch, calc_hessian=False)\n",
        "\n",
        "        for p, g in zip(model.parameters(), grads):\n",
        "            p.grad = g\n",
        "\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "        losses.append(float(loss.item()))\n",
        "\n",
        "        # pull projection stats from optimizer state (if you stored vr_pre_proj/vc_pre_proj)\n",
        "        vr_rel, vc_rel, vr_cos, vc_cos = [], [], [], []\n",
        "        vr_pre_norm, vr_post_norm, vc_pre_norm, vc_post_norm = [], [], [], []\n",
        "        matched = 0\n",
        "\n",
        "        state_dict = getattr(opt, \"state\", None)\n",
        "\n",
        "        if isinstance(state_dict, dict):\n",
        "            for st in state_dict.values():\n",
        "                if not isinstance(st, dict):\n",
        "                    continue\n",
        "\n",
        "                if all(k in st for k in (\"vr\", \"vc\", \"vr_pre_proj\", \"vc_pre_proj\")):\n",
        "                    matched += 1\n",
        "                    vr_pre, vr_post = _maybe(st[\"vr_pre_proj\"]), _maybe(st[\"vr\"])\n",
        "                    vc_pre, vc_post = _maybe(st[\"vc_pre_proj\"]), _maybe(st[\"vc\"])\n",
        "\n",
        "                    # norms\n",
        "                    vr_pre_norm.append(_norm(vr_pre))\n",
        "                    vr_post_norm.append(_norm(vr_post))\n",
        "                    vc_pre_norm.append(_norm(vc_pre))\n",
        "                    vc_post_norm.append(_norm(vc_post))\n",
        "\n",
        "                    # changes\n",
        "                    vr_rel.append(_rel_change(vr_pre, vr_post))\n",
        "                    vc_rel.append(_rel_change(vc_pre, vc_post))\n",
        "                    vr_cos.append(_cosine_sim(vr_pre, vr_post))  # safe cosine\n",
        "                    vc_cos.append(_cosine_sim(vc_pre, vc_post))\n",
        "\n",
        "\n",
        "        step_metrics.append({\n",
        "            \"step\": step,\n",
        "            \"loss\": float(loss.item()),\n",
        "            \"matched_states\": matched,\n",
        "\n",
        "            \"vr_pre_norm\": float(np.nanmean(vr_pre_norm)) if vr_pre_norm else float(\"nan\"),\n",
        "            \"vr_post_norm\": float(np.nanmean(vr_post_norm)) if vr_post_norm else float(\"nan\"),\n",
        "            \"vc_pre_norm\": float(np.nanmean(vc_pre_norm)) if vc_pre_norm else float(\"nan\"),\n",
        "            \"vc_post_norm\": float(np.nanmean(vc_post_norm)) if vc_post_norm else float(\"nan\"),\n",
        "\n",
        "            \"vr_rel\": float(np.mean(vr_rel)) if vr_rel else float(\"nan\"),\n",
        "            \"vc_rel\": float(np.mean(vc_rel)) if vc_rel else float(\"nan\"),\n",
        "            \"vr_cos\": float(np.mean(vr_cos)) if vr_cos else float(\"nan\"),\n",
        "            \"vc_cos\": float(np.mean(vc_cos)) if vc_cos else float(\"nan\"),\n",
        "        })\n",
        "\n",
        "    return {\n",
        "        \"projection_spec\": projection_spec,\n",
        "        \"beta1\": beta1,\n",
        "        \"loss_start\": losses[0] if losses else None,\n",
        "        \"loss_end\": losses[-1] if losses else None,\n",
        "        \"metrics\": step_metrics,\n",
        "    }\n",
        "\n",
        "# --- run sweep ---\n",
        "all_runs = []\n",
        "t0 = time.time()\n",
        "\n",
        "for spec in PROJECTION_SPECS:\n",
        "    for beta1 in (0.0, 0.9):\n",
        "        print(f\"Running spec='{spec}' beta1={beta1} ...\")\n",
        "        all_runs.append(run_one_projection_spec(spec, beta1))\n",
        "\n",
        "print(\"Done. total runs:\", len(all_runs), \"elapsed_sec:\", time.time() - t0)\n",
        "\n",
        "out_payload = {\n",
        "    \"meta\": {\n",
        "        \"seed\": SEED,\n",
        "        \"lr\": LR_PROJ,\n",
        "        \"weight_decay\": WD_PROJ,\n",
        "        \"max_batches\": MAX_BATCHES,\n",
        "        \"batch_size\": BATCH_SIZE_PROJ,\n",
        "        \"projection_specs\": list(PROJECTION_SPECS),\n",
        "    },\n",
        "    \"runs\": all_runs,\n",
        "}\n",
        "\n",
        "out_path = os.path.join(RESULTS_DIR, \"optimizer_projection_test.json\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    json.dump(out_payload, f, indent=2)\n",
        "\n",
        "print(\"Saved:\", out_path)\n"
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "_imbL59LFO3r",
        "outputId": "ecf471a6-8028-4180-91e3-06fd2b10d1ac"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    beta1                                  projection  steps   vr_rel_mean  \\\n",
              "0     0.0                                 box:l=0,u=1    200  0.000000e+00   \n",
              "1     0.0                             box:l=0,u=1e-08    200  0.000000e+00   \n",
              "2     0.0                             box:l=0,u=1e-09    200  7.521221e-03   \n",
              "3     0.0                             box:l=0,u=1e-10    200  6.399449e-02   \n",
              "4     0.0                             box:l=0,u=1e-11    200  2.815176e-01   \n",
              "5     0.0                             box:l=0,u=1e-12    200  6.997876e-01   \n",
              "6     0.0                               box:l=0,u=1e6    200  0.000000e+00   \n",
              "7     0.0  l2_ball:scale=param_rms,base=1,mult=0.0001    200  0.000000e+00   \n",
              "8     0.0   l2_ball:scale=param_rms,base=1,mult=1e-06    200  0.000000e+00   \n",
              "9     0.0   l2_ball:scale=param_rms,base=1,mult=1e-08    200  6.818761e-02   \n",
              "10    0.0   l2_ball:scale=param_rms,base=1,mult=1e-10    200  7.008160e-01   \n",
              "11    0.0   l2_ball:scale=param_rms,base=1,mult=1e-12    200  9.950806e-01   \n",
              "12    0.0                                        none    200  0.000000e+00   \n",
              "13    0.0                                      nonneg    200  0.000000e+00   \n",
              "14    0.0                               simplex:s=1.0    200  1.070207e+06   \n",
              "15    0.9                                 box:l=0,u=1    200  0.000000e+00   \n",
              "16    0.9                             box:l=0,u=1e-08    200  0.000000e+00   \n",
              "17    0.9                             box:l=0,u=1e-09    200  6.924941e-03   \n",
              "18    0.9                             box:l=0,u=1e-10    200  4.304976e-02   \n",
              "19    0.9                             box:l=0,u=1e-11    200  2.946465e-01   \n",
              "20    0.9                             box:l=0,u=1e-12    200  6.485058e-01   \n",
              "21    0.9                               box:l=0,u=1e6    200  0.000000e+00   \n",
              "22    0.9  l2_ball:scale=param_rms,base=1,mult=0.0001    200  0.000000e+00   \n",
              "23    0.9   l2_ball:scale=param_rms,base=1,mult=1e-06    200  0.000000e+00   \n",
              "24    0.9   l2_ball:scale=param_rms,base=1,mult=1e-08    200  6.108647e-02   \n",
              "25    0.9   l2_ball:scale=param_rms,base=1,mult=1e-10    200  6.611323e-01   \n",
              "26    0.9   l2_ball:scale=param_rms,base=1,mult=1e-12    200  9.950516e-01   \n",
              "27    0.9                                        none    200  0.000000e+00   \n",
              "28    0.9                                      nonneg    200  0.000000e+00   \n",
              "29    0.9                               simplex:s=1.0    200  3.292186e+06   \n",
              "\n",
              "    vr_rel_p95    vr_rel_max  vr_active_%   vc_rel_mean  vc_rel_p95  \\\n",
              "0     0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "1     0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "2     0.022620  9.461258e-02        100.0  3.589418e-03    0.010555   \n",
              "3     0.195711  4.513849e-01        100.0  5.940768e-02    0.185531   \n",
              "4     0.532220  8.070680e-01        100.0  2.697438e-01    0.533470   \n",
              "5     0.886791  9.799144e-01        100.0  6.995329e-01    0.854887   \n",
              "6     0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "7     0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "8     0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "9     0.168765  3.483125e-01         99.5  4.300517e-02    0.121290   \n",
              "10    0.887915  9.805832e-01        100.0  7.198050e-01    0.904506   \n",
              "11    0.999054  9.997859e-01        100.0  9.955513e-01    0.999178   \n",
              "12    0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "13    0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "14    0.172943  2.140414e+08        100.0  5.701892e+05    0.172943   \n",
              "15    0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "16    0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "17    0.020446  8.876699e-02        100.0  5.308228e-03    0.015896   \n",
              "18    0.130922  3.779296e-01        100.0  4.761606e-02    0.142443   \n",
              "19    0.540660  7.716413e-01        100.0  3.260538e-01    0.581515   \n",
              "20    0.837679  9.677670e-01        100.0  6.458738e-01    0.806150   \n",
              "21    0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "22    0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "23    0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "24    0.150926  2.874323e-01         99.5  4.021644e-02    0.107700   \n",
              "25    0.855118  9.743547e-01        100.0  6.965264e-01    0.891396   \n",
              "26    0.999119  9.997933e-01        100.0  9.962287e-01    0.999316   \n",
              "27    0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "28    0.000000  0.000000e+00          0.0  0.000000e+00    0.000000   \n",
              "29    0.172943  6.584373e+08        100.0  1.424503e+06    0.172943   \n",
              "\n",
              "      vc_rel_max  ...  vr_cos_min  vc_cos_mean  vc_cos_min  loss_start  \\\n",
              "0   0.000000e+00  ...    1.000000     1.000000    1.000000    0.167440   \n",
              "1   0.000000e+00  ...    1.000000     1.000000    1.000000    0.173084   \n",
              "2   6.372707e-02  ...    0.977733     0.999932    0.994600    0.170057   \n",
              "3   4.864655e-01  ...    0.884987     0.996655    0.899546    0.170880   \n",
              "4   7.645293e-01  ...    0.763494     0.961927    0.779905    0.170326   \n",
              "5   9.585844e-01  ...    0.618875     0.794344    0.659073    0.169236   \n",
              "6   0.000000e+00  ...    1.000000     1.000000    1.000000    0.167099   \n",
              "7   0.000000e+00  ...    1.000000     1.000000    1.000000    0.170543   \n",
              "8   0.000000e+00  ...    1.000000     1.000000    1.000000    0.172142   \n",
              "9   2.916704e-01  ...    1.000000     1.000000    1.000000    0.168850   \n",
              "10  9.824745e-01  ...    1.000000     1.000000    1.000000    0.172769   \n",
              "11  9.997962e-01  ...         NaN          NaN         NaN    0.170833   \n",
              "12  0.000000e+00  ...    1.000000     1.000000    1.000000    0.170316   \n",
              "13  0.000000e+00  ...    1.000000     1.000000    1.000000    0.168599   \n",
              "14  1.140378e+08  ...    0.513778     0.997932    0.586487    0.167229   \n",
              "15  0.000000e+00  ...    1.000000     1.000000    1.000000    0.176031   \n",
              "16  0.000000e+00  ...    1.000000     1.000000    1.000000    0.167721   \n",
              "17  9.265922e-02  ...    0.985730     0.999868    0.989832    0.171650   \n",
              "18  4.188044e-01  ...    0.924183     0.997933    0.931009    0.168656   \n",
              "19  7.523942e-01  ...    0.789544     0.943178    0.765933    0.171510   \n",
              "20  9.170313e-01  ...    0.624180     0.822165    0.677949    0.171535   \n",
              "21  0.000000e+00  ...    1.000000     1.000000    1.000000    0.170728   \n",
              "22  0.000000e+00  ...    1.000000     1.000000    1.000000    0.170139   \n",
              "23  0.000000e+00  ...    1.000000     1.000000    1.000000    0.165409   \n",
              "24  2.599851e-01  ...    1.000000     1.000000    1.000000    0.171407   \n",
              "25  9.801586e-01  ...    1.000000     1.000000    1.000000    0.177750   \n",
              "26  9.998362e-01  ...         NaN          NaN         NaN    0.168976   \n",
              "27  0.000000e+00  ...    1.000000     1.000000    1.000000    0.170325   \n",
              "28  0.000000e+00  ...    1.000000     1.000000    1.000000    0.172126   \n",
              "29  2.849005e+08  ...    0.542510     0.997835    0.567103    0.169964   \n",
              "\n",
              "    loss_end  matched_states_mean  vr_pre_norm_mean  vr_post_norm_mean  \\\n",
              "0   0.169205                  6.0      2.534424e-09       2.534424e-09   \n",
              "1   0.165977                  6.0      2.161803e-09       2.161803e-09   \n",
              "2   0.171322                  6.0      1.927867e-09       1.912921e-09   \n",
              "3   0.173588                  6.0      6.245025e-10       5.695546e-10   \n",
              "4   0.172437                  6.0      1.394598e-10       8.335460e-11   \n",
              "5   0.165856                  6.0      1.360660e-10       1.089492e-11   \n",
              "6   0.168706                  6.0      2.524481e-09       2.524481e-09   \n",
              "7   0.167198                  6.0      2.734572e-09       2.734572e-09   \n",
              "8   0.170000                  6.0      2.234302e-09       2.234302e-09   \n",
              "9   0.172670                  6.0      5.470785e-10       4.789768e-10   \n",
              "10  0.174915                  6.0      1.159836e-10       6.312421e-12   \n",
              "11  0.165134                  6.0      1.293432e-10       6.365198e-14   \n",
              "12  0.168290                  6.0      1.817394e-09       1.817394e-09   \n",
              "13  0.169203                  6.0      1.603191e-09       1.603191e-09   \n",
              "14  0.168668                  6.0      9.712010e-02       1.022299e-01   \n",
              "15  0.172115                  6.0      2.608326e-09       2.608326e-09   \n",
              "16  0.170706                  6.0      1.907215e-09       1.907215e-09   \n",
              "17  0.174718                  6.0      1.906565e-09       1.883207e-09   \n",
              "18  0.168975                  6.0      5.854870e-10       5.578912e-10   \n",
              "19  0.170100                  6.0      1.602694e-10       8.302122e-11   \n",
              "20  0.173596                  6.0      1.190489e-10       1.030948e-11   \n",
              "21  0.175025                  6.0      2.117142e-09       2.117142e-09   \n",
              "22  0.172024                  6.0      2.613099e-09       2.613099e-09   \n",
              "23  0.170602                  6.0      1.974606e-09       1.974606e-09   \n",
              "24  0.173564                  6.0      4.726302e-10       4.134474e-10   \n",
              "25  0.170053                  6.0      1.467630e-10       6.314605e-12   \n",
              "26  0.169896                  6.0      1.065305e-10       6.396818e-14   \n",
              "27  0.168462                  6.0      2.045493e-09       2.045493e-09   \n",
              "28  0.171733                  6.0      1.496424e-09       1.496424e-09   \n",
              "29  0.165664                  6.0      9.712010e-02       1.022299e-01   \n",
              "\n",
              "    vc_pre_norm_mean  vc_post_norm_mean  \n",
              "0       1.585288e-09       1.585288e-09  \n",
              "1       1.259594e-09       1.259594e-09  \n",
              "2       1.307409e-09       1.302382e-09  \n",
              "3       4.007302e-10       3.672376e-10  \n",
              "4       9.859487e-11       6.377454e-11  \n",
              "5       8.887698e-11       1.016928e-11  \n",
              "6       1.903456e-09       1.903456e-09  \n",
              "7       1.734238e-09       1.734238e-09  \n",
              "8       1.482614e-09       1.482614e-09  \n",
              "9       5.033299e-10       4.680807e-10  \n",
              "10      7.536501e-11       6.316533e-12  \n",
              "11      7.867043e-11       6.365303e-14  \n",
              "12      1.262752e-09       1.262752e-09  \n",
              "13      1.129273e-09       1.129273e-09  \n",
              "14      9.712010e-02       1.022299e-01  \n",
              "15      1.693627e-09       1.693627e-09  \n",
              "16      1.269396e-09       1.269396e-09  \n",
              "17      1.360323e-09       1.351051e-09  \n",
              "18      3.726090e-10       3.509911e-10  \n",
              "19      1.124873e-10       5.722829e-11  \n",
              "20      7.737615e-11       9.495710e-12  \n",
              "21      1.429457e-09       1.429457e-09  \n",
              "22      1.595298e-09       1.595298e-09  \n",
              "23      1.339134e-09       1.339134e-09  \n",
              "24      4.005213e-10       3.667011e-10  \n",
              "25      8.970747e-11       6.323013e-12  \n",
              "26      7.037172e-11       6.396818e-14  \n",
              "27      1.564998e-09       1.564998e-09  \n",
              "28      8.889774e-10       8.889774e-10  \n",
              "29      9.712010e-02       1.022299e-01  \n",
              "\n",
              "[30 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bb121b6-f63f-49d1-bf1b-ab90d65bc7dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>beta1</th>\n",
              "      <th>projection</th>\n",
              "      <th>steps</th>\n",
              "      <th>vr_rel_mean</th>\n",
              "      <th>vr_rel_p95</th>\n",
              "      <th>vr_rel_max</th>\n",
              "      <th>vr_active_%</th>\n",
              "      <th>vc_rel_mean</th>\n",
              "      <th>vc_rel_p95</th>\n",
              "      <th>vc_rel_max</th>\n",
              "      <th>...</th>\n",
              "      <th>vr_cos_min</th>\n",
              "      <th>vc_cos_mean</th>\n",
              "      <th>vc_cos_min</th>\n",
              "      <th>loss_start</th>\n",
              "      <th>loss_end</th>\n",
              "      <th>matched_states_mean</th>\n",
              "      <th>vr_pre_norm_mean</th>\n",
              "      <th>vr_post_norm_mean</th>\n",
              "      <th>vc_pre_norm_mean</th>\n",
              "      <th>vc_post_norm_mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.167440</td>\n",
              "      <td>0.169205</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.534424e-09</td>\n",
              "      <td>2.534424e-09</td>\n",
              "      <td>1.585288e-09</td>\n",
              "      <td>1.585288e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e-08</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.173084</td>\n",
              "      <td>0.165977</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.161803e-09</td>\n",
              "      <td>2.161803e-09</td>\n",
              "      <td>1.259594e-09</td>\n",
              "      <td>1.259594e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e-09</td>\n",
              "      <td>200</td>\n",
              "      <td>7.521221e-03</td>\n",
              "      <td>0.022620</td>\n",
              "      <td>9.461258e-02</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.589418e-03</td>\n",
              "      <td>0.010555</td>\n",
              "      <td>6.372707e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.977733</td>\n",
              "      <td>0.999932</td>\n",
              "      <td>0.994600</td>\n",
              "      <td>0.170057</td>\n",
              "      <td>0.171322</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.927867e-09</td>\n",
              "      <td>1.912921e-09</td>\n",
              "      <td>1.307409e-09</td>\n",
              "      <td>1.302382e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e-10</td>\n",
              "      <td>200</td>\n",
              "      <td>6.399449e-02</td>\n",
              "      <td>0.195711</td>\n",
              "      <td>4.513849e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.940768e-02</td>\n",
              "      <td>0.185531</td>\n",
              "      <td>4.864655e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.884987</td>\n",
              "      <td>0.996655</td>\n",
              "      <td>0.899546</td>\n",
              "      <td>0.170880</td>\n",
              "      <td>0.173588</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.245025e-10</td>\n",
              "      <td>5.695546e-10</td>\n",
              "      <td>4.007302e-10</td>\n",
              "      <td>3.672376e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e-11</td>\n",
              "      <td>200</td>\n",
              "      <td>2.815176e-01</td>\n",
              "      <td>0.532220</td>\n",
              "      <td>8.070680e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.697438e-01</td>\n",
              "      <td>0.533470</td>\n",
              "      <td>7.645293e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.763494</td>\n",
              "      <td>0.961927</td>\n",
              "      <td>0.779905</td>\n",
              "      <td>0.170326</td>\n",
              "      <td>0.172437</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.394598e-10</td>\n",
              "      <td>8.335460e-11</td>\n",
              "      <td>9.859487e-11</td>\n",
              "      <td>6.377454e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e-12</td>\n",
              "      <td>200</td>\n",
              "      <td>6.997876e-01</td>\n",
              "      <td>0.886791</td>\n",
              "      <td>9.799144e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.995329e-01</td>\n",
              "      <td>0.854887</td>\n",
              "      <td>9.585844e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.618875</td>\n",
              "      <td>0.794344</td>\n",
              "      <td>0.659073</td>\n",
              "      <td>0.169236</td>\n",
              "      <td>0.165856</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.360660e-10</td>\n",
              "      <td>1.089492e-11</td>\n",
              "      <td>8.887698e-11</td>\n",
              "      <td>1.016928e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e6</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.167099</td>\n",
              "      <td>0.168706</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.524481e-09</td>\n",
              "      <td>2.524481e-09</td>\n",
              "      <td>1.903456e-09</td>\n",
              "      <td>1.903456e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=0.0001</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170543</td>\n",
              "      <td>0.167198</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.734572e-09</td>\n",
              "      <td>2.734572e-09</td>\n",
              "      <td>1.734238e-09</td>\n",
              "      <td>1.734238e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-06</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.172142</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.234302e-09</td>\n",
              "      <td>2.234302e-09</td>\n",
              "      <td>1.482614e-09</td>\n",
              "      <td>1.482614e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-08</td>\n",
              "      <td>200</td>\n",
              "      <td>6.818761e-02</td>\n",
              "      <td>0.168765</td>\n",
              "      <td>3.483125e-01</td>\n",
              "      <td>99.5</td>\n",
              "      <td>4.300517e-02</td>\n",
              "      <td>0.121290</td>\n",
              "      <td>2.916704e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.168850</td>\n",
              "      <td>0.172670</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.470785e-10</td>\n",
              "      <td>4.789768e-10</td>\n",
              "      <td>5.033299e-10</td>\n",
              "      <td>4.680807e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-10</td>\n",
              "      <td>200</td>\n",
              "      <td>7.008160e-01</td>\n",
              "      <td>0.887915</td>\n",
              "      <td>9.805832e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>7.198050e-01</td>\n",
              "      <td>0.904506</td>\n",
              "      <td>9.824745e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.172769</td>\n",
              "      <td>0.174915</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.159836e-10</td>\n",
              "      <td>6.312421e-12</td>\n",
              "      <td>7.536501e-11</td>\n",
              "      <td>6.316533e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-12</td>\n",
              "      <td>200</td>\n",
              "      <td>9.950806e-01</td>\n",
              "      <td>0.999054</td>\n",
              "      <td>9.997859e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>9.955513e-01</td>\n",
              "      <td>0.999178</td>\n",
              "      <td>9.997962e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.170833</td>\n",
              "      <td>0.165134</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.293432e-10</td>\n",
              "      <td>6.365198e-14</td>\n",
              "      <td>7.867043e-11</td>\n",
              "      <td>6.365303e-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>none</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170316</td>\n",
              "      <td>0.168290</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.817394e-09</td>\n",
              "      <td>1.817394e-09</td>\n",
              "      <td>1.262752e-09</td>\n",
              "      <td>1.262752e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>nonneg</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.168599</td>\n",
              "      <td>0.169203</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.603191e-09</td>\n",
              "      <td>1.603191e-09</td>\n",
              "      <td>1.129273e-09</td>\n",
              "      <td>1.129273e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>simplex:s=1.0</td>\n",
              "      <td>200</td>\n",
              "      <td>1.070207e+06</td>\n",
              "      <td>0.172943</td>\n",
              "      <td>2.140414e+08</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.701892e+05</td>\n",
              "      <td>0.172943</td>\n",
              "      <td>1.140378e+08</td>\n",
              "      <td>...</td>\n",
              "      <td>0.513778</td>\n",
              "      <td>0.997932</td>\n",
              "      <td>0.586487</td>\n",
              "      <td>0.167229</td>\n",
              "      <td>0.168668</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.712010e-02</td>\n",
              "      <td>1.022299e-01</td>\n",
              "      <td>9.712010e-02</td>\n",
              "      <td>1.022299e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.176031</td>\n",
              "      <td>0.172115</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.608326e-09</td>\n",
              "      <td>2.608326e-09</td>\n",
              "      <td>1.693627e-09</td>\n",
              "      <td>1.693627e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e-08</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.167721</td>\n",
              "      <td>0.170706</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.907215e-09</td>\n",
              "      <td>1.907215e-09</td>\n",
              "      <td>1.269396e-09</td>\n",
              "      <td>1.269396e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e-09</td>\n",
              "      <td>200</td>\n",
              "      <td>6.924941e-03</td>\n",
              "      <td>0.020446</td>\n",
              "      <td>8.876699e-02</td>\n",
              "      <td>100.0</td>\n",
              "      <td>5.308228e-03</td>\n",
              "      <td>0.015896</td>\n",
              "      <td>9.265922e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>0.985730</td>\n",
              "      <td>0.999868</td>\n",
              "      <td>0.989832</td>\n",
              "      <td>0.171650</td>\n",
              "      <td>0.174718</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.906565e-09</td>\n",
              "      <td>1.883207e-09</td>\n",
              "      <td>1.360323e-09</td>\n",
              "      <td>1.351051e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e-10</td>\n",
              "      <td>200</td>\n",
              "      <td>4.304976e-02</td>\n",
              "      <td>0.130922</td>\n",
              "      <td>3.779296e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4.761606e-02</td>\n",
              "      <td>0.142443</td>\n",
              "      <td>4.188044e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.924183</td>\n",
              "      <td>0.997933</td>\n",
              "      <td>0.931009</td>\n",
              "      <td>0.168656</td>\n",
              "      <td>0.168975</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.854870e-10</td>\n",
              "      <td>5.578912e-10</td>\n",
              "      <td>3.726090e-10</td>\n",
              "      <td>3.509911e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e-11</td>\n",
              "      <td>200</td>\n",
              "      <td>2.946465e-01</td>\n",
              "      <td>0.540660</td>\n",
              "      <td>7.716413e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3.260538e-01</td>\n",
              "      <td>0.581515</td>\n",
              "      <td>7.523942e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.789544</td>\n",
              "      <td>0.943178</td>\n",
              "      <td>0.765933</td>\n",
              "      <td>0.171510</td>\n",
              "      <td>0.170100</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.602694e-10</td>\n",
              "      <td>8.302122e-11</td>\n",
              "      <td>1.124873e-10</td>\n",
              "      <td>5.722829e-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e-12</td>\n",
              "      <td>200</td>\n",
              "      <td>6.485058e-01</td>\n",
              "      <td>0.837679</td>\n",
              "      <td>9.677670e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.458738e-01</td>\n",
              "      <td>0.806150</td>\n",
              "      <td>9.170313e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.624180</td>\n",
              "      <td>0.822165</td>\n",
              "      <td>0.677949</td>\n",
              "      <td>0.171535</td>\n",
              "      <td>0.173596</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.190489e-10</td>\n",
              "      <td>1.030948e-11</td>\n",
              "      <td>7.737615e-11</td>\n",
              "      <td>9.495710e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e6</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170728</td>\n",
              "      <td>0.175025</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.117142e-09</td>\n",
              "      <td>2.117142e-09</td>\n",
              "      <td>1.429457e-09</td>\n",
              "      <td>1.429457e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.9</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=0.0001</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170139</td>\n",
              "      <td>0.172024</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.613099e-09</td>\n",
              "      <td>2.613099e-09</td>\n",
              "      <td>1.595298e-09</td>\n",
              "      <td>1.595298e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.9</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-06</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.165409</td>\n",
              "      <td>0.170602</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.974606e-09</td>\n",
              "      <td>1.974606e-09</td>\n",
              "      <td>1.339134e-09</td>\n",
              "      <td>1.339134e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.9</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-08</td>\n",
              "      <td>200</td>\n",
              "      <td>6.108647e-02</td>\n",
              "      <td>0.150926</td>\n",
              "      <td>2.874323e-01</td>\n",
              "      <td>99.5</td>\n",
              "      <td>4.021644e-02</td>\n",
              "      <td>0.107700</td>\n",
              "      <td>2.599851e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.171407</td>\n",
              "      <td>0.173564</td>\n",
              "      <td>6.0</td>\n",
              "      <td>4.726302e-10</td>\n",
              "      <td>4.134474e-10</td>\n",
              "      <td>4.005213e-10</td>\n",
              "      <td>3.667011e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.9</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-10</td>\n",
              "      <td>200</td>\n",
              "      <td>6.611323e-01</td>\n",
              "      <td>0.855118</td>\n",
              "      <td>9.743547e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>6.965264e-01</td>\n",
              "      <td>0.891396</td>\n",
              "      <td>9.801586e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.177750</td>\n",
              "      <td>0.170053</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.467630e-10</td>\n",
              "      <td>6.314605e-12</td>\n",
              "      <td>8.970747e-11</td>\n",
              "      <td>6.323013e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.9</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-12</td>\n",
              "      <td>200</td>\n",
              "      <td>9.950516e-01</td>\n",
              "      <td>0.999119</td>\n",
              "      <td>9.997933e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>9.962287e-01</td>\n",
              "      <td>0.999316</td>\n",
              "      <td>9.998362e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.168976</td>\n",
              "      <td>0.169896</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.065305e-10</td>\n",
              "      <td>6.396818e-14</td>\n",
              "      <td>7.037172e-11</td>\n",
              "      <td>6.396818e-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.9</td>\n",
              "      <td>none</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.170325</td>\n",
              "      <td>0.168462</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.045493e-09</td>\n",
              "      <td>2.045493e-09</td>\n",
              "      <td>1.564998e-09</td>\n",
              "      <td>1.564998e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.9</td>\n",
              "      <td>nonneg</td>\n",
              "      <td>200</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.172126</td>\n",
              "      <td>0.171733</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.496424e-09</td>\n",
              "      <td>1.496424e-09</td>\n",
              "      <td>8.889774e-10</td>\n",
              "      <td>8.889774e-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.9</td>\n",
              "      <td>simplex:s=1.0</td>\n",
              "      <td>200</td>\n",
              "      <td>3.292186e+06</td>\n",
              "      <td>0.172943</td>\n",
              "      <td>6.584373e+08</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.424503e+06</td>\n",
              "      <td>0.172943</td>\n",
              "      <td>2.849005e+08</td>\n",
              "      <td>...</td>\n",
              "      <td>0.542510</td>\n",
              "      <td>0.997835</td>\n",
              "      <td>0.567103</td>\n",
              "      <td>0.169964</td>\n",
              "      <td>0.165664</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.712010e-02</td>\n",
              "      <td>1.022299e-01</td>\n",
              "      <td>9.712010e-02</td>\n",
              "      <td>1.022299e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30 rows × 22 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bb121b6-f63f-49d1-bf1b-ab90d65bc7dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6bb121b6-f63f-49d1-bf1b-ab90d65bc7dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6bb121b6-f63f-49d1-bf1b-ab90d65bc7dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-71667d25-a5e5-416a-93bc-ec730d594b56\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-71667d25-a5e5-416a-93bc-ec730d594b56')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-71667d25-a5e5-416a-93bc-ec730d594b56 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_05ab9482-0657-4cab-9a94-7e62e6acacdb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_05ab9482-0657-4cab-9a94-7e62e6acacdb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    beta1                                  projection         score  \\\n",
              "0     0.0                                 box:l=0,u=1  0.000000e+00   \n",
              "1     0.0                             box:l=0,u=1e-08  0.000000e+00   \n",
              "2     0.0                               box:l=0,u=1e6  0.000000e+00   \n",
              "3     0.0  l2_ball:scale=param_rms,base=1,mult=0.0001  0.000000e+00   \n",
              "4     0.0   l2_ball:scale=param_rms,base=1,mult=1e-06  0.000000e+00   \n",
              "5     0.0                                        none  0.000000e+00   \n",
              "6     0.0                                      nonneg  0.000000e+00   \n",
              "7     0.0                             box:l=0,u=1e-09  1.111064e-02   \n",
              "8     0.0   l2_ball:scale=param_rms,base=1,mult=1e-08  1.111928e-01   \n",
              "9     0.0                             box:l=0,u=1e-10  1.234022e-01   \n",
              "10    0.0                             box:l=0,u=1e-11  5.512614e-01   \n",
              "11    0.0                             box:l=0,u=1e-12  1.399321e+00   \n",
              "12    0.0   l2_ball:scale=param_rms,base=1,mult=1e-10  1.420621e+00   \n",
              "13    0.0   l2_ball:scale=param_rms,base=1,mult=1e-12  1.990632e+00   \n",
              "14    0.0                               simplex:s=1.0  1.640396e+06   \n",
              "15    0.9                                 box:l=0,u=1  0.000000e+00   \n",
              "16    0.9                             box:l=0,u=1e-08  0.000000e+00   \n",
              "17    0.9                               box:l=0,u=1e6  0.000000e+00   \n",
              "18    0.9  l2_ball:scale=param_rms,base=1,mult=0.0001  0.000000e+00   \n",
              "19    0.9   l2_ball:scale=param_rms,base=1,mult=1e-06  0.000000e+00   \n",
              "20    0.9                                        none  0.000000e+00   \n",
              "21    0.9                                      nonneg  0.000000e+00   \n",
              "22    0.9                             box:l=0,u=1e-09  1.223317e-02   \n",
              "23    0.9                             box:l=0,u=1e-10  9.066582e-02   \n",
              "24    0.9   l2_ball:scale=param_rms,base=1,mult=1e-08  1.013029e-01   \n",
              "25    0.9                             box:l=0,u=1e-11  6.207002e-01   \n",
              "26    0.9                             box:l=0,u=1e-12  1.294380e+00   \n",
              "27    0.9   l2_ball:scale=param_rms,base=1,mult=1e-10  1.357659e+00   \n",
              "28    0.9   l2_ball:scale=param_rms,base=1,mult=1e-12  1.991280e+00   \n",
              "29    0.9                               simplex:s=1.0  4.716689e+06   \n",
              "\n",
              "     vr_rel_mean   vc_rel_mean  vr_active_%  vc_active_%  loss_end  \n",
              "0   0.000000e+00  0.000000e+00          0.0          0.0  0.169205  \n",
              "1   0.000000e+00  0.000000e+00          0.0          0.0  0.165977  \n",
              "2   0.000000e+00  0.000000e+00          0.0          0.0  0.168706  \n",
              "3   0.000000e+00  0.000000e+00          0.0          0.0  0.167198  \n",
              "4   0.000000e+00  0.000000e+00          0.0          0.0  0.170000  \n",
              "5   0.000000e+00  0.000000e+00          0.0          0.0  0.168290  \n",
              "6   0.000000e+00  0.000000e+00          0.0          0.0  0.169203  \n",
              "7   7.521221e-03  3.589418e-03        100.0        100.0  0.171322  \n",
              "8   6.818761e-02  4.300517e-02         99.5         99.5  0.172670  \n",
              "9   6.399449e-02  5.940768e-02        100.0        100.0  0.173588  \n",
              "10  2.815176e-01  2.697438e-01        100.0        100.0  0.172437  \n",
              "11  6.997876e-01  6.995329e-01        100.0        100.0  0.165856  \n",
              "12  7.008160e-01  7.198050e-01        100.0        100.0  0.174915  \n",
              "13  9.950806e-01  9.955513e-01        100.0        100.0  0.165134  \n",
              "14  1.070207e+06  5.701892e+05        100.0        100.0  0.168668  \n",
              "15  0.000000e+00  0.000000e+00          0.0          0.0  0.172115  \n",
              "16  0.000000e+00  0.000000e+00          0.0          0.0  0.170706  \n",
              "17  0.000000e+00  0.000000e+00          0.0          0.0  0.175025  \n",
              "18  0.000000e+00  0.000000e+00          0.0          0.0  0.172024  \n",
              "19  0.000000e+00  0.000000e+00          0.0          0.0  0.170602  \n",
              "20  0.000000e+00  0.000000e+00          0.0          0.0  0.168462  \n",
              "21  0.000000e+00  0.000000e+00          0.0          0.0  0.171733  \n",
              "22  6.924941e-03  5.308228e-03        100.0        100.0  0.174718  \n",
              "23  4.304976e-02  4.761606e-02        100.0        100.0  0.168975  \n",
              "24  6.108647e-02  4.021644e-02         99.5         99.5  0.173564  \n",
              "25  2.946465e-01  3.260538e-01        100.0        100.0  0.170100  \n",
              "26  6.485058e-01  6.458738e-01        100.0        100.0  0.173596  \n",
              "27  6.611323e-01  6.965264e-01        100.0        100.0  0.170053  \n",
              "28  9.950516e-01  9.962287e-01        100.0        100.0  0.169896  \n",
              "29  3.292186e+06  1.424503e+06        100.0        100.0  0.165664  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b397e4d-5ccf-4bc0-9c3a-62fe86038bd6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>beta1</th>\n",
              "      <th>projection</th>\n",
              "      <th>score</th>\n",
              "      <th>vr_rel_mean</th>\n",
              "      <th>vc_rel_mean</th>\n",
              "      <th>vr_active_%</th>\n",
              "      <th>vc_active_%</th>\n",
              "      <th>loss_end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.169205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.165977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e6</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.168706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=0.0001</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.167198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.170000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>none</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.168290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>nonneg</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.169203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e-09</td>\n",
              "      <td>1.111064e-02</td>\n",
              "      <td>7.521221e-03</td>\n",
              "      <td>3.589418e-03</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.171322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-08</td>\n",
              "      <td>1.111928e-01</td>\n",
              "      <td>6.818761e-02</td>\n",
              "      <td>4.300517e-02</td>\n",
              "      <td>99.5</td>\n",
              "      <td>99.5</td>\n",
              "      <td>0.172670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e-10</td>\n",
              "      <td>1.234022e-01</td>\n",
              "      <td>6.399449e-02</td>\n",
              "      <td>5.940768e-02</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.173588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e-11</td>\n",
              "      <td>5.512614e-01</td>\n",
              "      <td>2.815176e-01</td>\n",
              "      <td>2.697438e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.172437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0</td>\n",
              "      <td>box:l=0,u=1e-12</td>\n",
              "      <td>1.399321e+00</td>\n",
              "      <td>6.997876e-01</td>\n",
              "      <td>6.995329e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.165856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-10</td>\n",
              "      <td>1.420621e+00</td>\n",
              "      <td>7.008160e-01</td>\n",
              "      <td>7.198050e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.174915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-12</td>\n",
              "      <td>1.990632e+00</td>\n",
              "      <td>9.950806e-01</td>\n",
              "      <td>9.955513e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.165134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0</td>\n",
              "      <td>simplex:s=1.0</td>\n",
              "      <td>1.640396e+06</td>\n",
              "      <td>1.070207e+06</td>\n",
              "      <td>5.701892e+05</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.168668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e-08</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.170706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e6</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.175025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.9</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=0.0001</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.9</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-06</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.170602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.9</td>\n",
              "      <td>none</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.168462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.9</td>\n",
              "      <td>nonneg</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.171733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e-09</td>\n",
              "      <td>1.223317e-02</td>\n",
              "      <td>6.924941e-03</td>\n",
              "      <td>5.308228e-03</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.174718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e-10</td>\n",
              "      <td>9.066582e-02</td>\n",
              "      <td>4.304976e-02</td>\n",
              "      <td>4.761606e-02</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.168975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.9</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-08</td>\n",
              "      <td>1.013029e-01</td>\n",
              "      <td>6.108647e-02</td>\n",
              "      <td>4.021644e-02</td>\n",
              "      <td>99.5</td>\n",
              "      <td>99.5</td>\n",
              "      <td>0.173564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e-11</td>\n",
              "      <td>6.207002e-01</td>\n",
              "      <td>2.946465e-01</td>\n",
              "      <td>3.260538e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.170100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.9</td>\n",
              "      <td>box:l=0,u=1e-12</td>\n",
              "      <td>1.294380e+00</td>\n",
              "      <td>6.485058e-01</td>\n",
              "      <td>6.458738e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.173596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.9</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-10</td>\n",
              "      <td>1.357659e+00</td>\n",
              "      <td>6.611323e-01</td>\n",
              "      <td>6.965264e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.170053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.9</td>\n",
              "      <td>l2_ball:scale=param_rms,base=1,mult=1e-12</td>\n",
              "      <td>1.991280e+00</td>\n",
              "      <td>9.950516e-01</td>\n",
              "      <td>9.962287e-01</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.169896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.9</td>\n",
              "      <td>simplex:s=1.0</td>\n",
              "      <td>4.716689e+06</td>\n",
              "      <td>3.292186e+06</td>\n",
              "      <td>1.424503e+06</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.165664</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b397e4d-5ccf-4bc0-9c3a-62fe86038bd6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b397e4d-5ccf-4bc0-9c3a-62fe86038bd6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b397e4d-5ccf-4bc0-9c3a-62fe86038bd6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b5ddd9e6-ddfb-4528-9d31-034174518ea5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5ddd9e6-ddfb-4528-9d31-034174518ea5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b5ddd9e6-ddfb-4528-9d31-034174518ea5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(rank[[\\\"beta1\\\", \\\"projection\\\", \\\"score\\\", \\\"vr_rel_mean\\\", \\\"vc_rel_mean\\\", \\\"vr_active_%\\\", \\\"vc_active_%\\\", \\\"loss_end\\\"]])\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"beta1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4576928649440469,\n        \"min\": 0.0,\n        \"max\": 0.9,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"projection\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"box:l=0,u=1e-10\",\n          \"box:l=0,u=1e-12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 901932.1732254828,\n        \"min\": 0.0,\n        \"max\": 4716689.167746345,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.0,\n          0.011110639326701251\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vr_rel_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 625588.9289387934,\n        \"min\": 0.0,\n        \"max\": 3292186.394706505,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.0,\n          0.007521221057201426\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vc_rel_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 276785.52803495957,\n        \"min\": 0.0,\n        \"max\": 1424502.77303984,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.0,\n          0.0035894182694998257\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vr_active_%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50.71006157388872,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vc_active_%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50.71006157388872,\n        \"min\": 0.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loss_end\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002807567888073716,\n        \"min\": 0.16513362526893616,\n        \"max\": 0.17502467334270477,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.1700526475906372,\n          0.17211522161960602\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "source": [
        "# =========================\n",
        "# Adafactor Projection Test: SUMMARY (replace this whole cell)\n",
        "# =========================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def _safe(vals, fn, default=float(\"nan\")):\n",
        "    vals = [v for v in vals if not np.isnan(v)]\n",
        "    return float(fn(vals)) if len(vals) else default\n",
        "\n",
        "def _pct_active(vals, tol=1e-12):\n",
        "    vals = [v for v in vals if not np.isnan(v)]\n",
        "    if not vals:\n",
        "        return float(\"nan\")\n",
        "    return 100.0 * float(np.mean([v > tol for v in vals]))\n",
        "\n",
        "rows = []\n",
        "for run in all_runs:\n",
        "    metrics = run[\"metrics\"]\n",
        "\n",
        "    vr_pre_n = [m[\"vr_pre_norm\"] for m in metrics]\n",
        "    vr_post_n = [m[\"vr_post_norm\"] for m in metrics]\n",
        "    vc_pre_n = [m[\"vc_pre_norm\"] for m in metrics]\n",
        "    vc_post_n = [m[\"vc_post_norm\"] for m in metrics]\n",
        "    matched = [m[\"matched_states\"] for m in metrics]\n",
        "\n",
        "    vr_rel = [m[\"vr_rel\"] for m in metrics]\n",
        "    vc_rel = [m[\"vc_rel\"] for m in metrics]\n",
        "    vr_cos = [m[\"vr_cos\"] for m in metrics]\n",
        "    vc_cos = [m[\"vc_cos\"] for m in metrics]\n",
        "    losses = [m[\"loss\"] for m in metrics]\n",
        "\n",
        "    rows.append({\n",
        "        \"beta1\": run[\"beta1\"],\n",
        "        \"projection\": run[\"projection_spec\"],\n",
        "        \"steps\": len(metrics),\n",
        "\n",
        "        \"vr_rel_mean\": _safe(vr_rel, np.mean),\n",
        "        \"vr_rel_p95\":  _safe(vr_rel, lambda z: np.percentile(z, 95)),\n",
        "        \"vr_rel_max\":  _safe(vr_rel, np.max),\n",
        "        \"vr_active_%\": _pct_active(vr_rel),\n",
        "\n",
        "        \"vc_rel_mean\": _safe(vc_rel, np.mean),\n",
        "        \"vc_rel_p95\":  _safe(vc_rel, lambda z: np.percentile(z, 95)),\n",
        "        \"vc_rel_max\":  _safe(vc_rel, np.max),\n",
        "        \"vc_active_%\": _pct_active(vc_rel),\n",
        "\n",
        "        \"vr_cos_mean\": _safe(vr_cos, np.mean),\n",
        "        \"vr_cos_min\":  _safe(vr_cos, np.min),\n",
        "        \"vc_cos_mean\": _safe(vc_cos, np.mean),\n",
        "        \"vc_cos_min\":  _safe(vc_cos, np.min),\n",
        "\n",
        "        \"loss_start\": float(losses[0]) if losses else float(\"nan\"),\n",
        "        \"loss_end\":   float(losses[-1]) if losses else float(\"nan\"),\n",
        "        \"matched_states_mean\": _safe(matched, np.mean),\n",
        "\n",
        "        \"vr_pre_norm_mean\": _safe(vr_pre_n, np.mean),\n",
        "        \"vr_post_norm_mean\": _safe(vr_post_n, np.mean),\n",
        "        \"vc_pre_norm_mean\": _safe(vc_pre_n, np.mean),\n",
        "        \"vc_post_norm_mean\": _safe(vc_post_n, np.mean),\n",
        "\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values(by=[\"beta1\", \"projection\"]).reset_index(drop=True)\n",
        "display(df)\n",
        "\n",
        "# Optional: simple ranking (lower mean rel-change = \"less intrusive projection\")\n",
        "rank = df.copy()\n",
        "rank[\"score\"] = rank[\"vr_rel_mean\"].fillna(0) + rank[\"vc_rel_mean\"].fillna(0)\n",
        "rank = rank.sort_values(by=[\"beta1\", \"score\"], ascending=[True, True]).reset_index(drop=True)\n",
        "display(rank[[\"beta1\", \"projection\", \"score\", \"vr_rel_mean\", \"vc_rel_mean\", \"vr_active_%\", \"vc_active_%\", \"loss_end\"]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These blocks are running the mild projection we found to have impact on the Adafactor vectors, for a training size we will be able to compare to the ones without any projections."
      ],
      "metadata": {
        "id": "Ud4Cto6etv9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Projection specs: control / mild / extreme\n",
        "# =========================\n",
        "\n",
        "# Sweeps you already ran (keep for short diagnostics & write-up)\n",
        "L2_MULTS_ALL = [1e-12, 1e-10, 1e-8, 1e-6, 1e-4]\n",
        "BOX_US_ALL   = [1e-12, 1e-11, 1e-10, 1e-9, 1e-8]\n",
        "\n",
        "CONTROL_SPECS = [\n",
        "    \"none\",\n",
        "]\n",
        "\n",
        "# Mild = activates but not overly destructive in your 200-step table:\n",
        "# - L2 mult=1e-8 looked \"mild\"\n",
        "# - Box u=1e-9 looked \"mild\"\n",
        "MILD_SPECS = [\n",
        "    \"l2_ball:scale=param_rms,base=1,mult=1e-8\",\n",
        "    \"box:l=0,u=1e-9\",\n",
        "]\n",
        "\n",
        "# Extreme = intentionally strong; keep for write-up but do NOT long-run\n",
        "EXTREME_SPECS = [\n",
        "    \"l2_ball:scale=param_rms,base=1,mult=1e-10\",\n",
        "    \"l2_ball:scale=param_rms,base=1,mult=1e-12\",\n",
        "    \"box:l=0,u=1e-11\",\n",
        "    \"box:l=0,u=1e-12\",\n",
        "    \"simplex:s=1.0\",   # optional if you want the \"stress test\" example\n",
        "]\n",
        "\n",
        "# Optional: keep the full short-sweep list (for quick tests only)\n",
        "SHORT_SWEEP_SPECS = (\n",
        "    CONTROL_SPECS\n",
        "    + [f\"l2_ball:scale=param_rms,base=1,mult={m}\" for m in L2_MULTS_ALL]\n",
        "    + [f\"box:l=0,u={u}\" for u in BOX_US_ALL]\n",
        ")\n",
        "\n",
        "# Long runs: only baseline + mild (these are the ones you actually train longer)\n",
        "LONG_RUN_SPECS = CONTROL_SPECS + MILD_SPECS\n",
        "\n",
        "print(\"CONTROL:\", CONTROL_SPECS)\n",
        "print(\"MILD:\", MILD_SPECS)\n",
        "print(\"EXTREME (no long runs):\", EXTREME_SPECS)\n",
        "print(\"LONG_RUN_SPECS:\", LONG_RUN_SPECS)\n"
      ],
      "metadata": {
        "id": "VJc-G-l9trJx",
        "outputId": "68fd5d3f-b48b-409d-fdfe-2df6fc2aa047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CONTROL: ['none']\n",
            "MILD: ['l2_ball:scale=param_rms,base=1,mult=1e-8', 'box:l=0,u=1e-9']\n",
            "EXTREME (no long runs): ['l2_ball:scale=param_rms,base=1,mult=1e-10', 'l2_ball:scale=param_rms,base=1,mult=1e-12', 'box:l=0,u=1e-11', 'box:l=0,u=1e-12', 'simplex:s=1.0']\n",
            "LONG_RUN_SPECS: ['none', 'l2_ball:scale=param_rms,base=1,mult=1e-8', 'box:l=0,u=1e-9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, time\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# =========================\n",
        "# Persistent save location (Google Drive)\n",
        "# =========================\n",
        "BASE_DIR = \"/content/drive/MyDrive/adafactor_projection_test/\"\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, \"long_runs\")\n",
        "\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Saving long-run results to:\", RESULTS_DIR)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Long run hyperparameters (comparable to sweep baseline)\n",
        "# =========================\n",
        "BATCH_SIZE = 128\n",
        "LR = 0.002\n",
        "WD = 3.125e-05\n",
        "\n",
        "EPOCHS_LONG = 30       # recommended for \"do we improve loss?\"\n",
        "MAX_STEPS_PER_EPOCH = None  # set to e.g. 200 if you want speed; otherwise full epoch\n",
        "\n",
        "\n",
        "\n",
        "def run_long(projection_spec: str, beta1: float, seed: int = 0):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    model = Autoencoder().to(device)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # DataLoaders (assumes x_train, x_test exist)\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(x_train),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        torch.utils.data.TensorDataset(x_test),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        drop_last=False,\n",
        "    )\n",
        "\n",
        "    steps_per_epoch = len(train_loader) if MAX_STEPS_PER_EPOCH is None else min(len(train_loader), MAX_STEPS_PER_EPOCH)\n",
        "    total_steps = EPOCHS_LONG * steps_per_epoch\n",
        "\n",
        "    # Create optimizer (C1/C2 variants)\n",
        "    opt = create_optimizer(\n",
        "        \"C1\" if beta1 == 0.0 else \"C2\",\n",
        "        model,\n",
        "        epochs=EPOCHS_LONG,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        lr=LR,\n",
        "        wd=WD,\n",
        "        projection_spec=projection_spec,\n",
        "        track_projection_metrics=True,\n",
        "    )\n",
        "\n",
        "    def eval_loss():\n",
        "        model.eval()\n",
        "        losses = []\n",
        "        with torch.no_grad():\n",
        "            for (batch,) in test_loader:\n",
        "                batch = batch.to(device)\n",
        "                recon = model(batch)\n",
        "                loss = criterion(recon, batch)\n",
        "                losses.append(float(loss.item()))\n",
        "        model.train()\n",
        "        return float(np.mean(losses)) if losses else float(\"nan\")\n",
        "\n",
        "    history = []\n",
        "    t0 = time.time()\n",
        "\n",
        "    for epoch in range(EPOCHS_LONG):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "\n",
        "        for i, (batch,) in enumerate(train_loader):\n",
        "            if MAX_STEPS_PER_EPOCH is not None and i >= MAX_STEPS_PER_EPOCH:\n",
        "                break\n",
        "\n",
        "            batch = batch.to(device)\n",
        "            loss, grads, _ = autoencoder_oracle(model, criterion, batch, calc_hessian=False)\n",
        "\n",
        "            for p, g in zip(model.parameters(), grads):\n",
        "                p.grad = g\n",
        "\n",
        "            opt.step()\n",
        "            opt.zero_grad()\n",
        "            train_losses.append(float(loss.item()))\n",
        "\n",
        "        train_loss = float(np.mean(train_losses)) if train_losses else float(\"nan\")\n",
        "        test_loss = eval_loss()\n",
        "\n",
        "        history.append({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"test_loss\": test_loss,\n",
        "        })\n",
        "\n",
        "        # optional: print progress\n",
        "        if (epoch + 1) in (1, 5, 10, 20, 30, 50, 100) or (epoch + 1) == EPOCHS_LONG:\n",
        "            print(f\"[{projection_spec} | beta1={beta1}] epoch {epoch+1}/{EPOCHS_LONG} \"\n",
        "                  f\"train={train_loss:.6f} test={test_loss:.6f}\")\n",
        "\n",
        "    elapsed = time.time() - t0\n",
        "\n",
        "    # Save final weights\n",
        "    weights_path = os.path.join(\n",
        "        RESULTS_DIR,\n",
        "        f\"weights_beta1={beta1}_spec={projection_spec.replace(':','_').replace(',','_')}.pt\"\n",
        "    )\n",
        "    torch.save({\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"seed\": seed,\n",
        "        \"projection_spec\": projection_spec,\n",
        "        \"beta1\": beta1,\n",
        "        \"lr\": LR,\n",
        "        \"wd\": WD,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"epochs\": EPOCHS_LONG,\n",
        "        \"max_steps_per_epoch\": MAX_STEPS_PER_EPOCH,\n",
        "    }, weights_path)\n",
        "\n",
        "    # Save JSON history (for plots / reproducibility)\n",
        "    out = {\n",
        "        \"meta\": {\n",
        "            \"seed\": seed,\n",
        "            \"beta1\": beta1,\n",
        "            \"projection_spec\": projection_spec,\n",
        "            \"lr\": LR,\n",
        "            \"wd\": WD,\n",
        "            \"batch_size\": BATCH_SIZE,\n",
        "            \"epochs\": EPOCHS_LONG,\n",
        "            \"steps_per_epoch_used\": steps_per_epoch,\n",
        "            \"elapsed_sec\": elapsed,\n",
        "            \"weights_path\": weights_path,\n",
        "        },\n",
        "        \"history\": history,\n",
        "        \"final\": {\n",
        "            \"train_loss\": history[-1][\"train_loss\"],\n",
        "            \"test_loss\": history[-1][\"test_loss\"],\n",
        "            \"best_test_loss\": min(h[\"test_loss\"] for h in history),\n",
        "            \"best_epoch\": int(np.argmin([h[\"test_loss\"] for h in history]) + 1),\n",
        "        }\n",
        "    }\n",
        "\n",
        "    json_path = os.path.join(\n",
        "        RESULTS_DIR,\n",
        "        f\"run_beta1={beta1}_spec={projection_spec.replace(':','_').replace(',','_')}.json\"\n",
        "    )\n",
        "    with open(json_path, \"w\") as f:\n",
        "        json.dump(out, f, indent=2)\n",
        "\n",
        "    return out, json_path, weights_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyeCHy4MtKbo",
        "outputId": "c9219f4d-ed06-4e4b-8b10-41491ba0733e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Saving long-run results to: /content/drive/MyDrive/adafactor_projection_test/long_runs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_long = []\n",
        "for beta1 in (0.0, 0.9):\n",
        "    for spec in LONG_RUN_SPECS:\n",
        "        out, jp, wp = run_long(spec, beta1, seed=0)\n",
        "        all_long.append((out, jp, wp))\n",
        "\n",
        "print(\"Done long runs. Saved to:\", RESULTS_DIR)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "js3Pl9HkuGFQ",
        "outputId": "7c45785a-596b-42ef-b512-944f295fd07c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[none | beta1=0.0] epoch 1/30 train=0.170627 test=0.169811\n",
            "[none | beta1=0.0] epoch 5/30 train=0.168837 test=0.167941\n",
            "[none | beta1=0.0] epoch 10/30 train=0.164713 test=0.163481\n",
            "[none | beta1=0.0] epoch 20/30 train=0.136115 test=0.133436\n",
            "[none | beta1=0.0] epoch 30/30 train=0.096238 test=0.094549\n",
            "[l2_ball:scale=param_rms,base=1,mult=1e-8 | beta1=0.0] epoch 1/30 train=0.170583 test=0.169725\n",
            "[l2_ball:scale=param_rms,base=1,mult=1e-8 | beta1=0.0] epoch 5/30 train=0.168453 test=0.167497\n",
            "[l2_ball:scale=param_rms,base=1,mult=1e-8 | beta1=0.0] epoch 10/30 train=0.163243 test=0.161799\n",
            "[l2_ball:scale=param_rms,base=1,mult=1e-8 | beta1=0.0] epoch 20/30 train=0.126145 test=0.123060\n",
            "[l2_ball:scale=param_rms,base=1,mult=1e-8 | beta1=0.0] epoch 30/30 train=0.087289 test=0.085730\n",
            "[box:l=0,u=1e-9 | beta1=0.0] epoch 1/30 train=0.170626 test=0.169809\n",
            "[box:l=0,u=1e-9 | beta1=0.0] epoch 5/30 train=0.168790 test=0.167869\n",
            "[box:l=0,u=1e-9 | beta1=0.0] epoch 10/30 train=0.162181 test=0.160164\n",
            "[box:l=0,u=1e-9 | beta1=0.0] epoch 20/30 train=0.103745 test=0.101569\n",
            "[box:l=0,u=1e-9 | beta1=0.0] epoch 30/30 train=0.089980 test=0.089178\n",
            "[none | beta1=0.9] epoch 1/30 train=0.170647 test=0.169830\n",
            "[none | beta1=0.9] epoch 5/30 train=0.168794 test=0.167872\n",
            "[none | beta1=0.9] epoch 10/30 train=0.164053 test=0.162690\n",
            "[none | beta1=0.9] epoch 20/30 train=0.130353 test=0.127330\n",
            "[none | beta1=0.9] epoch 30/30 train=0.089999 test=0.088414\n",
            "[l2_ball:scale=param_rms,base=1,mult=1e-8 | beta1=0.9] epoch 1/30 train=0.170591 test=0.169722\n",
            "[l2_ball:scale=param_rms,base=1,mult=1e-8 | beta1=0.9] epoch 5/30 train=0.168311 test=0.167323\n",
            "[l2_ball:scale=param_rms,base=1,mult=1e-8 | beta1=0.9] epoch 10/30 train=0.162380 test=0.160801\n",
            "[l2_ball:scale=param_rms,base=1,mult=1e-8 | beta1=0.9] epoch 20/30 train=0.121480 test=0.118314\n",
            "[l2_ball:scale=param_rms,base=1,mult=1e-8 | beta1=0.9] epoch 30/30 train=0.082354 test=0.080842\n",
            "[box:l=0,u=1e-9 | beta1=0.9] epoch 1/30 train=0.170646 test=0.169828\n",
            "[box:l=0,u=1e-9 | beta1=0.9] epoch 5/30 train=0.168745 test=0.167794\n",
            "[box:l=0,u=1e-9 | beta1=0.9] epoch 10/30 train=0.160851 test=0.158513\n",
            "[box:l=0,u=1e-9 | beta1=0.9] epoch 20/30 train=0.100846 test=0.098864\n",
            "[box:l=0,u=1e-9 | beta1=0.9] epoch 30/30 train=0.087047 test=0.085973\n",
            "Done long runs. Saved to: /content/drive/MyDrive/adafactor_projection_test/long_runs\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}